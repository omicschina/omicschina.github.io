<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[常用工具网站总结]]></title>
    <url>%2F2017%2F09%2F14%2Fcommontool%2F</url>
    <content type="text"><![CDATA[在线制作流程图的网站，processOn Forest plot online 网页版LOESS 10 tips for making your R graphics look their best 7 QUALITY OF ANALYTICAL PROCEDURES Coursera, free courses Learn from Stanford Online, for anyone, anywhere, anytime METABOLITE IDENTIFICATION AND QUANTIFICATION (MS-BASED METABOLOMIC ANALYSIS) The R Tutorial Series provides a collection of user-friendly tutorials to people who want to learn how to use R for statistical analysis Open Source Tools for Mass Spectrometry Analysis 在线学习， 有很多R code， 很实用 宏基因组公众号文章目录, R , Python,文献笔记 未完待续…]]></content>
      <categories>
        <category>tools</category>
        <category>Metabolomics</category>
      </categories>
      <tags>
        <tag>Metabolomics</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Github和Hexo建独立博客]]></title>
    <url>%2F2017%2F09%2F14%2F2017-09-09-github-blog%2F</url>
    <content type="text"><![CDATA[参考了一篇非常好的文章，然后结合自己的实际问题，讲解如何使用github结合hexo建立个人的独立博客。 1. Hexo介绍Hexo是基于NodeJs的静态博客框架，简单、轻量，其生成的静态网页可以托管在Github和Heroku上。 . 超快速度. 支持MarkDown. 一键部署. 丰富的插件 下面以我的博客为例，shenxt.github.io为例，讲解如何部署自己的博客。 2. 环境准备2.1 安装node.js去nodejs官网下载对应系统的安装包，按提示安装。 检验安装成功，在git shell中输入一下代码： 1$ node -v 2.2 安装hexo1$ npm install hexo-cli -g 如果是mac，则需要输入： 1$ sudo npm install hexo-cli -g 3. 利用Hexo搭建一个博客3.1 创建博客目录shenxt@github.io123$ hexo init shenxt.github.io$ cd limedroid.github.io$ npm install 3.2 生成静态页面12$ hexo clean$ hexo g # g is generate 3.3 运行1$ hexo s -p3600# is server 然后可以打开浏览器，输入地址 localhost:3600 即可看到效果。 4 发一篇文章试试4.1 穿件一个新的博客1$ hexo new test 此时会在source/posts目录下生成test.md文件，输入一些内容，然后保存。 然后看一下效果: 123$ hexo clean$ hexo g$ hexo s -p3600# is server 然后可以打开浏览器，输入地址 localhost:3600 即可看到效果。 5 配置网站的设置大部分都在_config.yml文件夹中，详细配置可以查看官方文档。 下面只列出简单常用配置: .title -&gt; 网站标题.subtitle -&gt; 网站副标题.description -&gt; 网站描述.author -&gt; 您的名字.language -&gt; 网站使用的语言 注意：进行配置时，需要在冒号:后加一个英文空格。 6 更换主题在网站配置文件_config.yml中，配置theme。 1theme: next next是主题的名字。Hexo有不同的人贡献主题，可以到其官方网站上下载不同主题。看中某一主题之后，直接点击其名字，进入到其github界面，然后复制其网址，使用下面代码，即可下载主题到本地。 1git clone https://github.com/fi3ework/hexo-theme-archer 然后将博客的配置文件theme修改为archer即可。 观察效果： 123$ hexo clean$ hexo g$ hexo s -p3600# is server 7 部署到github上7.1 在github网页版上创建和自己账户名相同的仓库，比如我的账户为shenxt，因此，创建的仓库为shenxt.github.io。7.2 安装hexo-deployer-git1$ npm install hexo-deployer-git --save 7.3 网站配置git在网上的配置文件_config.yml中配置deploy。 123type: gitrepo: https://github.com/shenxt/shenxt.github.iobranch: master 7.4 部署1$ hexo d# d is deploy 贴标签，方便搜索8.1 两个确认. 首先确认博客的配置文件中有： 1tag_dir: tags . 然后确认主题的配置文件有： 1tags: tags 8.2 新建tags页面1$ hexo new page tags 此时会在source/下生成tags/index.md文件。 8.3 修改source/tags/index.md1234title: tagsdate: 2015-10-20 06:49:50type: &quot;tags&quot;comments: false 8.4 在文章中添加tags在你的文章中添加： 1234tags: - Tag1 - Tag2 - Tag3 其文件头部类似于： 123456title: TagEditTextdate: 2016-11-19 10:44:25tags: - Tag1 - Tag2 - Tag3 9 分类，给文章归档9.1 两个确认. 确认博客配置文件打开了 1category_dir: categories . 确认主题配置文件打开了 1categories: /categories 9.2 新建categories文件1hexo new page categories 9.3 修改categories/index.md1234title: categoriesdate: 2015-10-20 06:49:50type: &quot;categories&quot;comments: false 9.4 在文章中添加categories在文章中添加： 12categories: - cate 其文件头部类似： 1234title: TagEditTextdate: 2016-11-19 10:44:25categories: - cate 10 添加评论功能这里推荐使用韩国的来必力系统。参考这个博客进行设置。]]></content>
      <categories>
        <category>github technology</category>
      </categories>
      <tags>
        <tag>Chinese</tag>
        <tag>Github</tag>
        <tag>Blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用R爬取HMDB和KEGG数据库]]></title>
    <url>%2F2017%2F09%2F14%2F2016-12-03-keggandhmdb%2F</url>
    <content type="text"><![CDATA[R语言爬虫 虽然相对于python来说，R语言爬虫并不是那么流行，但是对于比较小的数据爬取量，使用R还是很方便的。R的数据爬取比较流行的是利用XML和RCurl包进行爬取，在这篇博客里面，我就利用XML和RCurl包进行KEGG和HMDB的数据爬取。 爬取KEGG通路信息 因为我需要的信息是KEGG的通路信息，比较简单，也就是每个通路包含哪些代谢物，只要人的metaboloic pathway，因此，我需要先将KEGG中的通路的网页链接拿到。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748library(XML)library(RCurl)##从kegg主页上抓取代谢通路的urlURL = getURL(&quot;http://www.genome.jp/kegg/pathway.html#global&quot;)doc &lt;- htmlParse(URL,encoding=&quot;utf-8&quot;)xpath.a &lt;- &quot;//a/@href&quot;node &lt;- getNodeSet(doc, xpath.a)url1 &lt;- sapply(node, as.character)xpath.b &lt;- &quot;//a[@href]&quot;name &lt;- getNodeSet(doc, xpath.b)name &lt;- sapply(name, xmlValue)name2 &lt;- name[59:247]url2 &lt;- url1[59:247]url3 &lt;- url2[grep(&quot;show&quot;, url2)]pathwat.name &lt;- NULLmetabolite.id &lt;- list()metabolite.name &lt;- list()for (i in 1:length(url3)) &#123; cat(paste(i,&quot;/&quot;,length(url3))) cat(&quot;\n&quot;) URL &lt;- paste(&quot;http://www.genome.jp&quot;, url3[i], sep = &quot;&quot;) URL = getURL(URL) doc&lt;-htmlParse(URL,encoding=&quot;utf-8&quot;) xpath &lt;- &quot;//option[@value=&apos;hsa&apos;]&quot; node&lt;-getNodeSet(doc, xpath) if (length(node) ==0 ) &#123; cat(&quot;No human pathwat.&quot;) next() &#125;else&#123; URL &lt;- paste(&quot;http://www.genome.jp&quot;, url3[i], sep = &quot;&quot;) URL &lt;- gsub(pattern = &quot;map=map&quot;, replacement = &quot;map=hsa&quot;, x = URL) doc&lt;-htmlParse(URL,encoding=&quot;utf-8&quot;) xpath1 &lt;- &quot;//title&quot; node&lt;-getNodeSet(doc, xpath1) pathway.name[i] &lt;- xmlValue(node[[1]]) pathway.name[i] &lt;- substr(pathway.name[i], start = 2, stop = nchar(pathway.name[i])-1) xpath2 &lt;- &quot;//area[@shape=&apos;circle&apos;]/@title&quot; node&lt;-getNodeSet(doc, xpath2) metabolite &lt;- lapply(node, function(x) as.character(x)) metabolite.name[[i]] &lt;- substr(metabolite, start = 9, nchar(metabolite)-1) metabolite.id[[i]] &lt;- substr(metabolite, start = 1, stop = 6) &#125;&#125; 下面对爬取到的代谢通路进行筛选。 12345678idx &lt;- which(!is.na(pathway.name))pathway.name1 &lt;- pathway.name[idx]metabolite.id1 &lt;- metabolite.id[idx]metabolite.name1 &lt;- metabolite.name[idx]pathway.name2 &lt;- pathway.name1[-c(83,84)]metabolite.id2 &lt;- metabolite.id1[-c(83,84)]metabolite.name2 &lt;- metabolite.name1[-c(83,84)] 将爬取到的信息保存输出。 1234567891011121314151617181920212223242526met.name &lt;- NULLmet.id &lt;- NULLpath.name &lt;- NULLfor(i in 1:length(pathway.name2)) &#123; met.name[i] &lt;- paste(metabolite.name2[[i]], collapse = &quot;;&quot;) met.id[i] &lt;- paste(metabolite.id2[[i]], collapse = &quot;;&quot;) path.name[i] &lt;- gsub(pattern = &quot;KEGG PATHWAY: &quot;, &quot;&quot;, pathway.name2[i]) path.name[i] &lt;- substr(path.name[i], start = 1, stop = nchar(path.name[i])-23)&#125;kegg &lt;- data.frame(path.name, met.name, met.id)write.csv(kegg, &quot;kegg.csv&quot;, row.names = F)save(path.name, file = &quot;path.name&quot;)save(met.name, file = &quot;met.name&quot;)save(met.id, file = &quot;met.id&quot;)kegg.met &lt;- list()kegg.met[[2]] &lt;- sapply(path.name, list)kegg.met[[1]] &lt;- metabolite.name2kegg.met[[3]] &lt;- metabolite.id2names(kegg.met) &lt;- c(&quot;gs&quot;, &quot;pathwaynames&quot;, &quot;metid&quot;)save(kegg.met, file = &quot;kegg.met&quot;) 爬取HMDB通路信息 首先爬取HMDB的通路信息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475##抓取HMDB通路信息library(XML)library(RCurl)hmdb.main &lt;- &quot;http://www.hmdb.ca/pathways?page=&quot;hmdb.main &lt;- paste(hmdb.main, c(2:46), sep = &quot;&quot;)hmdb.main &lt;- c(&quot;http://www.hmdb.ca/pathways&quot;, hmdb.main)##从HMDB主页上抓取代谢通路的urlpath.name &lt;- list()metabolite.id &lt;- list()spec &lt;- list()path.class &lt;- list()for (i in 40:length(hmdb.main)) &#123; cat(paste(&quot;page&quot;,i)) cat(&quot;:&quot;) URL = getURL(hmdb.main[i]) doc&lt;-htmlParse(URL,encoding=&quot;utf-8&quot;) xpath1 &lt;- &quot;//div[@class=&apos;panel-heading&apos;]&quot; node1 &lt;- getNodeSet(doc, xpath1) pathway.name &lt;- sapply(node1, xmlValue) cat(paste(length(pathway.name), &quot;pathways&quot;)) cat(&quot;\n&quot;) path.name[[i]] &lt;- pathway.name xpath2 &lt;- &quot;//div[@class=&apos;panel-body&apos;]&quot; node2 &lt;- getNodeSet(doc, xpath2) metabolite &lt;- sapply(node2, xmlValue) metabolite &lt;- unname(sapply(metabolite, function(x) &#123;gsub(&quot;Show&quot;, &quot; &quot;, x)&#125;)) idx &lt;- sapply(metabolite, function(x) &#123;gregexpr(&quot;HMDB[0-9]&#123;5&#125;&quot;, x)&#125;) met.id &lt;- list() for (j in 1:length(idx)) &#123; id &lt;- NULL for (k in 1:length(idx[[j]])) &#123; id[k] &lt;- substr(metabolite[j], idx[[j]][k], idx[[j]][k]+8) &#125; met.id[[j]] &lt;- id &#125; metabolite.id[[i]] &lt;- met.id xpath.a &lt;- &quot;//a[@class=&apos;link-out&apos;]/@href&quot; node&lt;-getNodeSet(doc, xpath.a) url1 &lt;- sapply(node, as.character) url1 &lt;- substr(url1, start = 1, stop = 29) url1 &lt;- url1[!duplicated(url1)] ###获取通路的人种和类别 species &lt;- NULL metabolic &lt;- NULL for (t in 1:length(url1)) &#123; cat(paste(&quot;t:&quot;,t));cat(&quot; &quot;) URL = getURL(url1[t]) doc &lt;- htmlParse(URL,encoding=&quot;utf-8&quot;) xpath &lt;- &quot;//div[@class=&apos;species&apos;]/text()&quot; node &lt;- getNodeSet(doc, xpath) species[t] &lt;- xmlValue(node[[1]]) xpath &lt;- &quot;//div[@id=&apos;des_subject&apos;]/text()&quot; node &lt;- getNodeSet(doc, xpath) metabolic[t] &lt;- xmlValue(node[[1]]) &#125; spec[[i]] &lt;- species path.class[[i]] &lt;- metabolic&#125; 对爬取到的代谢通路进行筛选。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051save(path.name, file = &quot;path.name&quot;)save(metabolite.id, file = &quot;metabolite.id&quot;)save(spec, file = &quot;spec&quot;)save(path.class, file = &quot;path.class&quot;)pathway.name &lt;- NULLmetabolite.ID &lt;- list()species &lt;- NULLpathway.class &lt;- NULLfor (i in 1:length(path.name)) &#123; pathway.name &lt;- c(pathway.name, path.name[[i]]) metabolite.ID &lt;- c(metabolite.ID, metabolite.id[[i]]) species &lt;- c(species, spec[[i]]) pathway.class &lt;- c(pathway.class, path.class[[i]])&#125;pathway.class &lt;- substr(x = pathway.class, 1, regexpr(&quot;\\\n&quot;, pathway.class)-1)metabolite.name &lt;- list()for (i in 1:length(metabolite.ID)) &#123; id &lt;- metabolite.ID[[i]] idx &lt;- match(id, hmdbdatabase[,1]) name &lt;- hmdbdatabase[idx,2] metabolite.name[[i]] &lt;- name&#125;a &lt;- unlist(lapply(metabolite.name, function(x) &#123;paste(x, collapse = &quot;;&quot;)&#125;))b &lt;- unlist(lapply(metabolite.ID, function(x) &#123;paste(x, collapse = &quot;;&quot;)&#125;))idx &lt;- grep(&quot;Metabolic&quot;, pathway.class)metabolite.name &lt;- metabolite.name[idx]metabolite.ID &lt;- metabolite.ID[idx]pathway.name &lt;- pathway.name[idx]pathway.class &lt;- pathway.class[idx]species &lt;- species[idx]hmdb.pathway &lt;- data.frame(pathway.name, pathway.class,a, b)[idx,]write.csv(hmdb.pathway, &quot;hmdb.pathway.csv&quot;)a &lt;- list()for (i in 1:length(pathway.name)) &#123; a[[i]] &lt;- pathway.name[i]&#125;pathway.name &lt;- ahmdb.met &lt;- list(gs = metabolite.name, pathwaynames = pathway.name, id = metabolite.ID)save(hmdb.met, file = &quot;hmdb.met&quot;) 爬取HMDB代谢物信息 首先，获得所有代谢物的页面链接。 12345678910111213141516171819202122232425###抓取HMDB代谢物信息library(XML)library(RCurl)hmdb.main &lt;- &quot;http://www.hmdb.ca/metabolites?c=hmdb_id&amp;d=up&amp;page=&quot;hmdb.main &lt;- paste(hmdb.main, c(2:1681), sep = &quot;&quot;)hmdb.main &lt;- c(&quot;http://www.hmdb.ca/metabolites&quot;, hmdb.main)##从HMDB主页上抓取代谢物的urlurl &lt;- NULLfor (i in 1:length(hmdb.main)) &#123; cat(i) cat(&quot; &quot;) URL = getURL(hmdb.main[i]) doc&lt;-htmlParse(URL,encoding=&quot;utf-8&quot;) xpath &lt;- &quot;//a[@href]/@href&quot; node&lt;-getNodeSet(doc, xpath) url1 &lt;- sapply(node, as.character) url1 &lt;- url1[grep(&quot;metabolites/HMDB&quot;, url1)] url1 &lt;- unique(url1) url &lt;- c(url, url1)&#125;url1 &lt;- paste(&quot;http://www.hmdb.ca/&quot;,url, sep = &quot;&quot;)save(url1, file = &quot;url1&quot;) 下面开始进行代谢物信息爬取。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970library(mailR)for (i in 1:400) &#123; cat(paste((i-1)*100+1,&quot;-&quot;,i*100,&quot;/&quot;, length(url1), sep = &quot;&quot;)) cat(&quot;\n&quot;) URL &lt;- getURL(url1[((i-1)*100+1):(i*100)]) doc &lt;- htmlParse(URL, encoding=&quot;utf-8&quot;) xpath1 &lt;- &quot;//tr&quot; node1 &lt;- getNodeSet(doc, xpath1) node1 &lt;- sapply(node1, xmlValue) HMDB_ID[((i-1)*100+1):(i*100)] &lt;- gsub(pattern = &quot;HMDB ID&quot;, replacement = &quot;&quot;,node1[grep(&quot;HMDB ID&quot;, node1)]) Common_Name[((i-1)*100+1):(i*100)] &lt;- gsub(&quot;Common Name&quot;, &quot;&quot;,node1[grep(&quot;Common Name&quot;, node1)]) temp &lt;- gsub(&quot;SynonymsValueSource&quot;, &quot;&quot;,node1[grep(&quot;Synonyms&quot;, node1)]) temp &lt;- gsub(&quot;Generator&quot;, &quot;;&quot;,temp) temp &lt;- gsub(&quot;ChEMBL&quot;, &quot;;&quot;,temp) temp &lt;- gsub(&quot;ChEBI&quot;, &quot;;&quot;,temp) Synonyms[((i-1)*100+1):(i*100)] &lt;- gsub(&quot;HMDB&quot;, &quot;;&quot;,temp) Chemical_Formula[((i-1)*100+1):(i*100)] &lt;- gsub(&quot;Chemical Formula&quot;, &quot;&quot;,node1[grep(&quot;Chemical Formula&quot;, node1)]) Monoisotopic_Molecular_Weight[((i-1)*100+1):(i*100)] &lt;- gsub(&quot;Monoisotopic Molecular Weight&quot;, &quot;&quot;,node1[grep(&quot;Monoisotopic Molecular Weight&quot;, node1)]) IUPAC_Name[((i-1)*100+1):(i*100)] &lt;- gsub(&quot;IUPAC Name&quot;, &quot;&quot;,node1[grep(&quot;IUPAC Name&quot;, node1)]) Traditional_Name[((i-1)*100+1):(i*100)] &lt;- gsub(&quot;Traditional Name&quot;, &quot;&quot;,node1[grep(&quot;Traditional Name&quot;, node1)]) CAS_Registry_Number[((i-1)*100+1):(i*100)] &lt;- gsub(&quot;CAS Registry Number&quot;, &quot;&quot;,node1[grep(&quot;CAS Registry Number&quot;, node1)]) Origin[((i-1)*100+1):(i*100)] &lt;- gsub(&quot;Origin&quot;, &quot;&quot;,node1[grep(&quot;Origin&quot;, node1)]) path &lt;- gsub(&quot;PathwaysNameSMPDB LinkKEGG Link&quot;, &quot;&quot;,node1[grep(&quot;Pathways&quot;, node1)]) Pathways[((i-1)*100+1):(i*100)] &lt;- substr(path, 1, stop = regexpr(&quot;SMP&quot;, path)-1) ##每100次保存一次 if (i*100 %in% seq(100, 60000, by = 100)) &#123; cat(&quot;save data...\n&quot;) save(HMDB_ID, Common_Name, Synonyms, Chemical_Formula, Monoisotopic_Molecular_Weight, IUPAC_Name, Traditional_Name, CAS_Registry_Number, Origin, Pathways, file = paste(&quot;hmdb.data&quot;,i*100)) send.mail(from = &quot;yourmail1@163.com&quot;, to = c(&quot;youmail20@163.com&quot;), subject = paste(&quot;WZZ GO ON:&quot;, i), body = paste(&quot;WZZ still go on&quot;, i), smtp = list(host.name = &quot;smtp.163.com&quot;, port = 465, user.name = &quot;yourmail1&quot;, passwd = &quot;passward&quot;, ssl = TRUE), authenticate = TRUE, send = TRUE) &#125;&#125; 因为代谢物信息比较大，可能需要一晚上，因此想到了没爬取100个，就给自己发一封邮件，来对程序进行监控。 写的比较粗糙，有时间再好好修改一下。]]></content>
  </entry>
  <entry>
    <title><![CDATA[MetDNA instruction]]></title>
    <url>%2F2017%2F09%2F14%2F2017-09-09-metdna-blog%2F</url>
    <content type="text"><![CDATA[Ⅰ数据准备MetDNA需要准备的数据包括一级数据peak table(csv格式)，二级数据(mgf格式)和样品信息sample.info(csv格式)。点击下载正离子demo数据和负离子demo数据。Table 1: demo数据信息 组别 个数 含义 QC 8 QC W03 10 野生型3天 W30 10 野生型30天 E03 10 突变型E3天 E30 10 突变型E30天 P03 10 突变型P3天 P30 10 突变型P30天 1. 一级数据一级数据可以是使用XCMS，MZmine，MS-DIAL或者其他软件处理之后的数据。第一列为代谢物峰的名字，”name”，第二列为”mz”，第三列为保留时间(RT)，且单位必须为秒，其他为样品的峰强度。 2. 二级数据二级质谱原始数据可以是使用QC样品采集的DDA或者targeted MS/MS数据。对于DDA数据来说，也可以是分段采集的二级数据。质谱原始二级数据需要使用ProteoWizard软件转为mgf格式，转换时参数设置参考下图。二级数据最多不能超过十个。Figure 2: ProteoWizard参数设置 3. 样品信息样品信息是样品的分组信息。第一列是样品名，”sample.name”，第二列是样品的分组信息，”group”。 Ⅱ 数据整理如果是正离子数据，请建立一个新的文件夹，命名为”POS”，如果是负离子数据，请建立一个新的文件夹命名为”NEG”，然后将一级数据，二级数据和样品信息放置于此文件夹下。并将该文件夹设置为工作路径。现在MetDNA部署在小服务器上，因此可以将数据放在小服务器中(labdata)。例如”V:/workreport/申小涛/demo/fly/POS”。 设置工作路径。12setwd(&quot;/mnt/data/samba/labdata/workreport/申小涛/demo/fly/POS&quot;)library(MetDNA) Ⅲ 数据处理1. 只对正离子或者负离子处理所有的步骤可以使用一个函数MetDNA全部完成。运行函数MetDNA。123456789101112MetDNA(ms1.file = &quot;data.csv&quot;, polarity = &quot;positive&quot;, column = &quot;hilic&quot;, ce = &quot;30&quot;, prefer.adduct = &quot;M+H&quot;, use.default.md = TRUE, threads = 3, group = c(&quot;W03&quot;, &quot;W30&quot;), uni.test = &quot;t&quot;, correct = TRUE, p.cutoff = 0.01, species = &quot;dme&quot;) 参数含义如下： ms1.file：一级数据的名字。 polarity：数据采集极性，”positive”或者”negative”。 column：使用的柱子类型，”hilic”或者”rp”。 ce：二级采集的碰撞能量，支持”10”，”15”，”20”，”25”，”30”，”35”，”35,15” (35±15)，”40”， “45”，”50”，”55”，”60”，”65”，”70”。 prefer.adduct：使用那些加合物形式的注释用于RT预测模型的建立，默认使用所有的注释，推荐正离子模式下使用”M+H”，负离子模式下使用”M-H”。 use.default.md：进行保留时间预测模型建立时，是否使用默认的分子描述符，如果设置为FALSE，则会根据你的数据自动选择分子描述符。 threads：使用线程数，默认为3，可以根据电脑本身配置进行修改。 group：要对哪些分组的样品进行分析，注意，计算fold change时，使用后面的样品除以前面的样品。 uni.test：单变量分析的方法，”t”，Student t test；”wilcox”，Wilcox test。 correct：是否需要对p值进行FDR校正。 p.cutoff：选择dysregulated peak时的p值cutoff。 species：所研究样品的物种来源，”dme”，果蝇；”hsa”，人类；”mmu”，小鼠；”rat”，大鼠，”bta”，牛；”gga”，Gallus gallus (鸡)；”dre”，Danio rerio (斑马鱼)；”cel”，Caenorharomyces elegans (线虫)；”sce”，Saccharomyces cerevisaiae (酵母)； “ath”，Arabidopsis thaliana (拟南芥)；”smm”，Schistosoma mansoni；”pfa”，Plasmodum falciparum 3D7；”tbr”，Trypanosoma brucei；”eco”， Escherichia coli K-12 MG1655(大肠杆菌)；”ppu”，Pseudomonas putida KT2440；”syf”，Synechococcus elongatus。 2. 对正负数据合并分析正负离子分别处理之后，可以使用函数metModule2函数合并正负离子模式的鉴定结果，进行dysregulated network analysis。运行函数MetModule21234567metModule2(group = c(&quot;W03&quot;, &quot;W30&quot;), uni.test = &quot;t&quot;, column = &quot;hilic&quot;, correct = TRUE, p.cutoff = 0.01, threads = 3, species = &quot;dme&quot;) 参数含义如下： group：要对哪些分组的样品进行分析，注意，计算fold change时，使用后面的样品除以前面的样品。 uni.test：单变量分析的方法，”t”，Student t test；”wilcox”，Wilcox test。 column：使用的柱子类型，”hilic”或者”rp”。 correct：是否需要对p值进行FDR校正。 p.cutoff：选择dysregulated peak时的p值cutoff。 threads：使用线程数，默认为3，可以根据电脑本身配置进行修改。 species：所研究样品的物种来源，”dme”，果蝇；”hsa”，人类；”mmu”，小鼠；”rat”，大鼠，”bta”，牛；”gga”，Gallus gallus (鸡)；”dre”，Danio rerio (斑马鱼)；”cel”，Caenorharomyces elegans (线虫)；”sce”，Saccharomyces cerevisaiae (酵母)； “ath”，Arabidopsis thaliana (拟南芥)；”smm”，Schistosoma mansoni；”pfa”，Plasmodum falciparum 3D7；”tbr”，Trypanosoma brucei；”eco”， Escherichia coli K-12 MG1655(大肠杆菌)；”ppu”，Pseudomonas putida KT2440；”syf”，Synechococcus elongatus。 运行函数analysisReport得到分析报告。1analysisReport(polarity = &quot;both&quot;) Ⅳ 运行结果1. 正离子或者负离子的运行结果MetDNA函数运行结束之后，所有的运行结果都存放在设置的路径中，包含二级谱图匹配结果，MRN注释结果，dysregulated network分析结果以及分析报告。如图5所示。 (1) MetDNA.parameters.csv记录此次运行所使用的参数。 (2) ms2_match_result_POS二级谱图匹配结果。包括一个csv文件，ms2.match.annotation.result.csv和一个文件夹，MS2_match_spectra。ms2.macth.annotation.result.csv是二级谱图匹配之后的结果，与MetAnalyzer处理之后的结果相同；MS2_match_spectra文件夹中包含了所有二级匹配图(Figure 6)。 (3) MRN_annotation_result_POS基于metabolic reacion network注释结果。包括两个csv文件，metABM.parameters.csv和MRN.annotation.result.csv。MRN.annotation.result.csv是使用MRN注释结果(Figure 8)。 其中： annotation.from.ID：该peak的该注释来自于哪个metabolite(ID); annotation.from.peak：该peak的该注释来自于哪个peak; ID：注释代谢物结果的KEGG ID; compound.name：注释结果的名字； isotope：同位素信息； adduct：加合物信息； Formula：化学结构式； score：注释打分； peak.group：peak group； confidence：对注释的peak group打分。 (4) Dysregulated_network_analsysi_result_POSDysregulated network分析的结果。其中包括一个pdf文件，volcano.plot.pdf(Figure: 9)，两个csv文件，metModule.parameters.csv和DNA.annotation.result.csv以及两个文件夹，module_information(Figure 10)和pathway_inforamtion (Figure 11)。1) volcano.plot是选取差异代谢物峰的火山图。 2) DNA.annotation.result.csv是通过dysregulated network对注释结果进行筛选以及KEGG database注释之后的注释结果。3) module_information文件夹中包含了dysregulated module的分析结果。其中module.result.csv是module的信息。module.overview.pdf是module结果的总览(Figure 10)。module.heatmap.pdf是对module进行定量分析之后的热图(Figure 11)。boxplot文件夹中包含了module在两组间的定量结果(Figure 12)。Module_MSE analysis文件夹中包含了对每个module进行功能注释(MSEA)的结果(Figure 13)。 3) pathway_information文件夹中包含了pathway的分析结果(Figure 14)。 其中： boxplot：该文件夹中含有每个pathway的定量信息; dysregulated.network.overview：该图表示dysregulated network的pathway分析结果; dysregulated.netwrok.MSEA.csv：dysregulated network的MSEA分析结果; dysregulated.netwrok.MSEA.pdf：dysregulated network的MSEA分析结果; dysregulated.networks.for.cytoscape.txt：用于cytoscape作图的数据； dysregulated.networks.attribute.txt：用于cytoscape作图的节点属性数据； pathway.heatmap.pdf：dysregulated network的pathway定量的heatmap。 (5) Analysis_report_POS对数据处理分析结果的总结。输出的结果存放在Analysis_report文件夹内。包括一份html格式的分析报告。]]></content>
      <categories>
        <category>R software</category>
        <category>Metabolomics</category>
      </categories>
      <tags>
        <tag>Chinese</tag>
        <tag>R</tag>
        <tag>Metabolomics</tag>
      </tags>
  </entry>
</search>
